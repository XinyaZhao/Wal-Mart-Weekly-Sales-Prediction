{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Pacakges\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import *\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "#from dstools import data_tools\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as pylab\n",
    "pylab.rcParams['figure.figsize'] = 8, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read sample data -- Department 1 ~ 20 of all stores\n",
    "data = pd.read_csv('data_merge.csv')\n",
    "data_dept = data[data['Dept']<=20]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert Sales Date\n",
    "data_dept.Sales_Date = pd.to_datetime(data_dept.Sales_Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute moving average of sales\n",
    "#Read CSV Data\n",
    "\n",
    "data = pd.read_csv('data_merge.csv')\n",
    "data_dept = data[data['Dept']<=20]  \n",
    "\n",
    "def moving_average(data_dept):\n",
    "    avgs = {}\n",
    "    for r in data_dept.index:\n",
    "        store = data_dept.loc[r].Store\n",
    "        dept =  data_dept.loc[r].Dept\n",
    "        date = data_dept.Sales_Date.dt.date.loc[r]\n",
    "        s = 0\n",
    "        c = 0\n",
    "        new_date = date - DateOffset(months = 1)\n",
    "        temp_d = data_dept[(data_dept.Store == store )&(data_dept.Dept == dept) \n",
    "                           &(data_dept.Sales_Date.dt.year == new_date.year) \n",
    "                           & (data_dept.Sales_Date.dt.month == new_date.month)]\n",
    "        s = s + sum(temp_d.Weekly_Sales)\n",
    "        c = c + len(temp_d)\n",
    "    \n",
    "\n",
    "    if c != 0:\n",
    "        avgs[r] = s/c\n",
    "    else:\n",
    "        avgs[r] = data_dept.loc[r].Weekly_Sales\n",
    "    return avgs\n",
    "\n",
    "mavgs = moving_average(data_dept)\n",
    "data_dept = data_dept.merge(mavgs,left_index=True,right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dummyize Store \n",
    "\n",
    "for i in range(1,46):\n",
    "    String = 'Store_'+ str(i)\n",
    "    data_dept[String] = pd.Series(data_dept['Store'] == i, dtype=int)\n",
    "data_dept.head()\n",
    "\n",
    "\n",
    "# Dummyize Department \n",
    "for i in range(1,21):\n",
    "    String = 'Dept'+ str(i)\n",
    "    data_dept[String] = pd.Series(data_dept['Dept'] == i, dtype=int)\n",
    "    \n",
    "# Dummyize Season \n",
    "for i in range(1,5):\n",
    "    String = 'Season' + str(i)\n",
    "    data_dept[String] = pd.Series(data_dept['Season'] == i, dtype=int)\n",
    "    \n",
    "#Dummyize Year, Month of Sale\n",
    "data_dept['Sales_Date'] =pd.to_datetime(data_dept.Sales_Date)\n",
    "year_dummies = pd.get_dummies(data_dept.Sales_Date.dt.year,prefix='Year_')\n",
    "month_dummies = pd.get_dummies(data_dept.Sales_Date.dt.month,prefix='Month_')\n",
    "week_dummies = pd.get_dummies(data_dept.Sales_Date.dt.week,prefix='Week_')\n",
    "data_dept = data_dept.merge(year_dummies,right_index=True,left_index=True)\n",
    "data_dept = data_dept.merge(month_dummies,right_index=True,left_index=True)\n",
    "data_dept = data_dept.merge(week_dummies,right_index=True,left_index=True)\n",
    "\n",
    "#Dummyize Month-week of Sale:\n",
    "\n",
    "# def week_of_month(dt):\n",
    "#     \"\"\" Returns the week of the month for the specified date.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     first_day = dt.replace(day=1)\n",
    "\n",
    "#     dom = dt.day\n",
    "#     adjusted_dom = dom + first_day.weekday()\n",
    "\n",
    "#     return int(ceil(adjusted_dom/7.0))\n",
    "\n",
    "# week_dummies = pd.get_dummies(data_dept.Sales_Date.apply(week_of_month),prefix='MonthWeek_')\n",
    "# data_dept = data_dept.merge(week_dummies,right_index = True, left_index= True)\n",
    "\n",
    "\n",
    "#Drop usless columns\n",
    "dropCols = ['Season','Sales_Date','Store','Dept','Weekly_Sales']\n",
    "data_dept= data_dept.drop(dropCols,1)\n",
    "\n",
    "#Convert Target Variable to Float\n",
    "data_dept['Target_Variable'] = data_dept['Target_Variable'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output the preprocessed data to a new file\n",
    "data_dept.to_csv('processed_data_week.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
